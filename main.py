from fastapi import FastAPI, UploadFile, File, Form, HTTPException, Request
from fastapi.responses import HTMLResponse, JSONResponse
from fastapi.staticfiles import StaticFiles
from fastapi.templating import Jinja2Templates
import uvicorn
import os
import sys
from typing import List, Dict, Any
import json
import aiofiles
from datetime import datetime
import PyPDF2
import hashlib
import re
import logging
from app.services.vector_search import create_vector_search_engine

# ë©”ëª¨ë¦¬ ê´€ë¦¬ ê°œì„ 
import gc
# ë¬¸ì„œ ì²˜ë¦¬ ì„¤ì •
MAX_CHUNK_SIZE = 1000  # ë¬¸ì ë‹¨ìœ„
MAX_MEMORY_USAGE = 8  # GB ë‹¨ìœ„
MAX_DOCUMENT_SIZE = 10 * 1024 * 1024  # 10MB ì œí•œ

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name%)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('logs/app.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# logs ë””ë ‰í† ë¦¬ ìƒì„±
os.makedirs("logs", exist_ok=True)

# ë²¡í„° ì—”ì§„ ì´ˆê¸°í™”ì— ì˜ˆì™¸ ì²˜ë¦¬ ì¶”ê°€
try:
    logger.info("ë²¡í„° ê²€ìƒ‰ ì—”ì§„ ì´ˆê¸°í™” ì‹œì‘")
    vector_engine = create_vector_search_engine()
    logger.info("ë²¡í„° ê²€ìƒ‰ ì—”ì§„ ì´ˆê¸°í™” ì™„ë£Œ")
except Exception as e:
    logger.error(f"ë²¡í„° ì—”ì§„ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    # ë°±ì—… ì²˜ë¦¬ ë˜ëŠ” ì•ˆì „ ëª¨ë“œë¡œ ì‹¤í–‰
    vector_engine = None

# FastAPI ì•± ìƒì„±
app = FastAPI(title="Document Search & Chat System", version="1.0.0")
logger.info("FastAPI ì•± ìƒì„± ì™„ë£Œ")

# ì •ì  íŒŒì¼ê³¼ í…œí”Œë¦¿ ì„¤ì •
app.mount("/static", StaticFiles(directory="static"), name="static")
templates = Jinja2Templates(directory="templates")

# ë””ë ‰í† ë¦¬ ì„¤ì •
UPLOAD_DIR = "uploads"
PROCESSED_DIR = "processed"
os.makedirs(UPLOAD_DIR, exist_ok=True)
os.makedirs(PROCESSED_DIR, exist_ok=True)
logger.info("ì—…ë¡œë“œ ë° ì²˜ë¦¬ ë””ë ‰í† ë¦¬ ìƒì„± ì™„ë£Œ")

# Ollama ì„¤ì •
OLLAMA_HOST = "http://localhost:11434"
MODEL_NAME = "llama3.2:1b"

# ë¬¸ì„œ ì²˜ë¦¬ í´ë˜ìŠ¤
class DocumentProcessor:
    def __init__(self):
        logger.info("DocumentProcessor ì´ˆê¸°í™”")

    def generate_document_id(self, filename: str) -> str:
        timestamp = str(int(datetime.now().timestamp() * 1000))
        unique_string = f"{filename}_{timestamp}"
        doc_id = hashlib.md5(unique_string.encode()).hexdigest()[:12]
        logger.debug(f"ë¬¸ì„œ ID ìƒì„±: {doc_id} (íŒŒì¼: {filename})")
        return doc_id

    async def extract_pdf_text(self, file_path: str) -> str:
        logger.info(f"PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹œì‘: {file_path}")
        try:
            with open(file_path, 'rb') as file:
                pdf_reader = PyPDF2.PdfReader(file)
                text = ""
                for page_num, page in enumerate(pdf_reader.pages):
                    text += page.extract_text() + "\n"
                    logger.debug(f"PDF í˜ì´ì§€ {page_num + 1} í…ìŠ¤íŠ¸ ì¶”ì¶œ ì™„ë£Œ")

                logger.info(f"PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ ì™„ë£Œ: {len(text)} ë¬¸ì")
                return text.strip()
        except Exception as e:
            logger.error(f"PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨: {file_path} - {str(e)}")
            raise Exception(f"PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨: {str(e)}")

    async def extract_txt_text(self, file_path: str) -> str:
        logger.info(f"í…ìŠ¤íŠ¸ íŒŒì¼ ì¶”ì¶œ ì‹œì‘: {file_path}")
        try:
            async with aiofiles.open(file_path, 'r', encoding='utf-8') as f:
                content = await f.read()
                logger.info(f"UTF-8ë¡œ í…ìŠ¤íŠ¸ íŒŒì¼ ì½ê¸° ì™„ë£Œ: {len(content)} ë¬¸ì")
                return content.strip()
        except UnicodeDecodeError:
            logger.warning(f"UTF-8 ì¸ì½”ë”© ì‹¤íŒ¨, CP949ë¡œ ì¬ì‹œë„: {file_path}")
            try:
                async with aiofiles.open(file_path, 'r', encoding='cp949') as f:
                    content = await f.read()
                    logger.info(f"CP949ë¡œ í…ìŠ¤íŠ¸ íŒŒì¼ ì½ê¸° ì™„ë£Œ: {len(content)} ë¬¸ì")
                    return content.strip()
            except:
                logger.warning(f"CP949 ì¸ì½”ë”© ì‹¤íŒ¨, latin-1ë¡œ ì¬ì‹œë„: {file_path}")
                async with aiofiles.open(file_path, 'r', encoding='latin-1') as f:
                    content = await f.read()
                    logger.info(f"latin-1ë¡œ í…ìŠ¤íŠ¸ íŒŒì¼ ì½ê¸° ì™„ë£Œ: {len(content)} ë¬¸ì")
                    return content.strip()

    async def extract_docx_text(self, file_path: str) -> str:
        logger.info(f"DOCX í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹œì‘: {file_path}")
        try:
            from docx import Document
            doc = Document(file_path)
            text = []
            for para_num, paragraph in enumerate(doc.paragraphs):
                text.append(paragraph.text)
                logger.debug(f"DOCX ë‹¨ë½ {para_num + 1} ì¶”ì¶œ ì™„ë£Œ")

            content = '\n'.join(text)
            logger.info(f"DOCX í…ìŠ¤íŠ¸ ì¶”ì¶œ ì™„ë£Œ: {len(content)} ë¬¸ì")
            return content
        except Exception as e:
            logger.error(f"DOCX í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨: {file_path} - {str(e)}")
            raise Exception(f"DOCX í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨: {str(e)}")

    async def process_file(self, file: UploadFile) -> Dict[str, Any]:
        logger.info(f"ğŸ“ [íŒŒì¼ ì²˜ë¦¬] ì‹œì‘ - {file.filename}")
        try:
            if not file.filename:
                logger.error("âŒ [ì²˜ë¦¬ ì‹¤íŒ¨] íŒŒì¼ ì´ë¦„ì´ ì—†ìŒ")
                raise ValueError("íŒŒì¼ ì´ë¦„ì´ ì—†ìŠµë‹ˆë‹¤.")

            # íŒŒì¼ ì €ì¥
            file_path = os.path.join(UPLOAD_DIR, file.filename)
            logger.info(f"ğŸ’¾ [íŒŒì¼ ì €ì¥] ê²½ë¡œ: {file_path}")

            async with aiofiles.open(file_path, 'wb') as f:
                content = await file.read()
                await f.write(content)

            logger.info(f"âœ… [ì €ì¥ ì™„ë£Œ] í¬ê¸°: {len(content):,} bytes")

            ext = file.filename.lower().split('.')[-1]
            logger.info(f"ğŸ“„ [íŒŒì¼ í˜•ì‹] {ext.upper()}")

            # í…ìŠ¤íŠ¸ ì¶”ì¶œ
            text_extract_start = datetime.now()
            if ext == 'pdf':
                content = await self.extract_pdf_text(file_path)
            elif ext in ['txt', 'md']:
                content = await self.extract_txt_text(file_path)
            elif ext == 'docx':
                content = await self.extract_docx_text(file_path)
            else:
                logger.error(f"âŒ [ì§€ì›í•˜ì§€ ì•ŠëŠ” í˜•ì‹] {ext}")
                raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹: {ext}")

            text_extract_time = (datetime.now() - text_extract_start).total_seconds()
            logger.info(f"â±ï¸ [í…ìŠ¤íŠ¸ ì¶”ì¶œ ì™„ë£Œ] {text_extract_time:.2f}ì´ˆ ì†Œìš”")

            file_stats = os.stat(file_path)
            document_id = self.generate_document_id(file.filename)

            metadata = {
                'id': document_id,
                'filename': file.filename,
                'content': content,
                'size': file_stats.st_size,
                'upload_time': datetime.now().isoformat(),
                'file_type': ext,
                'word_count': len(content.split()),
                'char_count': len(content),
                'filepath': file_path
            }

            processed_file_path = os.path.join(PROCESSED_DIR, f"{document_id}.json")
            logger.info(f"ğŸ’¾ [ë©”íƒ€ë°ì´í„° ì €ì¥] {processed_file_path}")

            async with aiofiles.open(processed_file_path, 'w', encoding='utf-8') as f:
                await f.write(json.dumps(metadata, ensure_ascii=False, indent=2))

            logger.info(f"âœ… [ì²˜ë¦¬ ì™„ë£Œ] ID: {document_id}")
            logger.info(f"ğŸ“Š [ë¬¸ì„œ í†µê³„] ë‹¨ì–´: {metadata['word_count']:,}ê°œ, ë¬¸ì: {metadata['char_count']:,}ê°œ")
            return metadata

        except Exception as e:
            logger.error(f"ğŸ’¥ [ì²˜ë¦¬ ì‹¤íŒ¨] íŒŒì¼: {file.filename} - ì˜¤ë¥˜: {str(e)}")
            raise Exception(f"íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")

# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
doc_processor = DocumentProcessor()

# ë¼ìš°íŠ¸ë“¤
@app.get("/", response_class=HTMLResponse)
async def home(request: Request):
    logger.info("í™ˆí˜ì´ì§€ ìš”ì²­")
    return templates.TemplateResponse("index.html", {"request": request})


@app.post("/api/upload")
async def upload_file(file: UploadFile = File(...)):
    upload_start_time = datetime.now()
    logger.info(f"ğŸ“¤ [ì—…ë¡œë“œ ì‹œì‘] íŒŒì¼: {file.filename}, ì‹œì‘ì‹œê°„: {upload_start_time.strftime('%H:%M:%S')}")

    if not file.filename:
        logger.error("âŒ [ì—…ë¡œë“œ ì‹¤íŒ¨] íŒŒì¼ ì´ë¦„ì´ ì—†ëŠ” ì—…ë¡œë“œ ìš”ì²­")
        raise HTTPException(status_code=400, detail="íŒŒì¼ ì´ë¦„ì´ ì—†ìŠµë‹ˆë‹¤.")

    try:
        # íŒŒì¼ í¬ê¸° ì²´í¬ ì¶”ê°€
        content = await file.read()
        file_size_mb = len(content) / (1024 * 1024)
        logger.info(f"ğŸ“Š [íŒŒì¼ ì •ë³´] í¬ê¸°: {file_size_mb:.2f}MB ({len(content):,} bytes)")

        # íŒŒì¼ í¬ì¸í„°ë¥¼ ì²˜ìŒìœ¼ë¡œ ë˜ëŒë¦¬ê¸°
        await file.seek(0)

        # íŒŒì¼ ì²˜ë¦¬
        logger.info("ğŸ”„ [ì²˜ë¦¬ ì¤‘] íŒŒì¼ ë¶„ì„ ë° í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹œì‘")
        doc_data = await doc_processor.process_file(file)

        # ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì— ë¬¸ì„œ ì¶”ê°€
        logger.info(f"ğŸ” [ë²¡í„°í™” ì‹œì‘] ë¬¸ì„œ ID: {doc_data['id']}")
        try:
            vector_engine.add_document(
                document_id=doc_data["id"],
                content=doc_data["content"],
                metadata=doc_data
            )
            logger.info(f"âœ… [ë²¡í„°í™” ì„±ê³µ] ë¬¸ì„œ ID: {doc_data['id']}")
        except Exception as e:
            logger.error(f"âŒ [ë²¡í„°í™” ì‹¤íŒ¨] ë¬¸ì„œ ID: {doc_data['id']} - ì˜¤ë¥˜: {str(e)}")
            # ë§Œì•½ ë²¡í„° DB ì¶”ê°€ì— ì‹¤íŒ¨í•˜ë©´ ì´ë¯¸ ì €ì¥ëœ íŒŒì¼ì„ ì •ë¦¬
            if os.path.exists(doc_data['filepath']):
                os.remove(doc_data['filepath'])
                logger.info(f"ğŸ§¹ [ì •ë¦¬ ì™„ë£Œ] ì›ë³¸ íŒŒì¼: {doc_data['filepath']}")
            if os.path.exists(os.path.join(PROCESSED_DIR, f"{doc_data['id']}.json")):
                os.remove(os.path.join(PROCESSED_DIR, f"{doc_data['id']}.json"))
                logger.info(f"ğŸ§¹ [ì •ë¦¬ ì™„ë£Œ] ë©”íƒ€ë°ì´í„°: {doc_data['id']}.json")
            raise HTTPException(status_code=500, detail=f"ë¬¸ì„œ ë²¡í„°í™” ì‹¤íŒ¨: {e}")

        # ì„±ê³µ ë¡œê·¸
        upload_end_time = datetime.now()
        processing_time = (upload_end_time - upload_start_time).total_seconds()

        logger.info(f"ğŸ‰ [ì—…ë¡œë“œ ì„±ê³µ] íŒŒì¼: {file.filename}")
        logger.info(f"ğŸ“‹ [ì²˜ë¦¬ ê²°ê³¼] ID: {doc_data['id']}, ë‹¨ì–´: {doc_data['word_count']:,}ê°œ, ë¬¸ì: {doc_data['char_count']:,}ê°œ")
        logger.info(f"â±ï¸ [ì²˜ë¦¬ ì‹œê°„] {processing_time:.2f}ì´ˆ")

        return JSONResponse(
            status_code=201,
            content={
                "message": "íŒŒì¼ ì—…ë¡œë“œ ë° ì²˜ë¦¬ ì„±ê³µ",
                "document": doc_data
            }
        )

    except HTTPException:
        # HTTPExceptionì€ ê·¸ëŒ€ë¡œ ì¬ë°œìƒ
        raise
    except Exception as e:
        upload_end_time = datetime.now()
        processing_time = (upload_end_time - upload_start_time).total_seconds()

        logger.error(f"ğŸ’¥ [ì—…ë¡œë“œ ì‹¤íŒ¨] íŒŒì¼: {file.filename}")
        logger.error(f"âŒ [ì˜¤ë¥˜ ë‚´ìš©] {str(e)}")
        logger.error(f"â±ï¸ [ì‹¤íŒ¨ê¹Œì§€ ì‹œê°„] {processing_time:.2f}ì´ˆ")

        raise HTTPException(status_code=500, detail=f"íŒŒì¼ ì—…ë¡œë“œ ì‹¤íŒ¨: {str(e)}")

@app.get("/api/documents")
async def get_documents():
    logger.info("ë¬¸ì„œ ëª©ë¡ ì¡°íšŒ ìš”ì²­")
    try:
        documents = []
        for filename in os.listdir(PROCESSED_DIR):
            if filename.endswith('.json'):
                file_path = os.path.join(PROCESSED_DIR, filename)
                async with aiofiles.open(file_path, 'r', encoding='utf-8') as f:
                    content = await f.read()
                    doc_data = json.loads(content)
                    doc_summary = {k: v for k, v in doc_data.items() if k != 'content'}
                    documents.append(doc_summary)

        documents.sort(key=lambda x: x['upload_time'], reverse=True)
        logger.info(f"ë¬¸ì„œ ëª©ë¡ ì¡°íšŒ ì™„ë£Œ: {len(documents)}ê°œ")
        return JSONResponse({"documents": documents})

    except Exception as e:
        logger.error(f"ë¬¸ì„œ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
        raise HTTPException(status_code=500, detail=f"ë¬¸ì„œ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")

@app.post("/api/search")
async def search_documents(request: Request):
    logger.info("ë¬¸ì„œ ê²€ìƒ‰ ìš”ì²­")
    try:
        data = await request.json()
        query = data.get("query", "").strip()
        logger.info(f"ê²€ìƒ‰ì–´: '{query}'")

        if not query:
            logger.warning("ë¹ˆ ê²€ìƒ‰ì–´ë¡œ ìš”ì²­")
            raise HTTPException(status_code=400, detail="ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")

        # ë²¡í„° ê²€ìƒ‰ì„ í†µí•´ ì˜ë¯¸ì ìœ¼ë¡œ ìœ ì‚¬í•œ ë¬¸ì„œ ì¡°ê°ì„ ê²€ìƒ‰í•©ë‹ˆë‹¤.
        logger.info("ë²¡í„° ê²€ìƒ‰ ì‹œì‘")
        vector_results = vector_engine.search_documents(
            query=query,
            n_results=10,
            score_threshold=None  # ë™ì  ì„ê³„ê°’ ì‚¬ìš©
        )
        logger.info(f"ë²¡í„° ê²€ìƒ‰ ì™„ë£Œ: {len(vector_results)}ê°œ ê²°ê³¼")

        # ê²°ê³¼ ì²˜ë¦¬
        results = []
        for res in vector_results:
            metadata = res.get('metadata', {})
            snippet = res.get('content', '')
            highlighted_snippet = re.sub(
                re.escape(query),
                f"<mark>{query}</mark>",
                snippet,
                flags=re.IGNORECASE
            )

            results.append({
                "id": metadata.get("id"),
                "filename": metadata.get("filename"),
                "file_type": metadata.get("file_type"),
                "upload_time": metadata.get("upload_time"),
                "content_snippet": highlighted_snippet,
                "similarity": res.get('similarity', 0),  # ìœ ì‚¬ë„ ì •ë³´ ì¶”ê°€
                "threshold_used": res.get('threshold_used', 0)  # ì‚¬ìš©ëœ ì„ê³„ê°’ ì¶”ê°€
            })

        logger.info(f"ê²€ìƒ‰ ê²°ê³¼ ì²˜ë¦¬ ì™„ë£Œ: {len(results)}ê°œ")
        return JSONResponse({
            "query": query,
            "results": results,
            "total_results": len(results)
        })

    except Exception as e:
        logger.error(f"ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}")
        raise HTTPException(status_code=500, detail=f"ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}")

@app.post("/api/chat")
async def chat_with_documents(request: Request):
    logger.info("ì±„íŒ… ìš”ì²­")
    try:
        import requests

        data = await request.json()
        question = data.get("message", "").strip()
        logger.info(f"ì§ˆë¬¸: '{question}'")

        if not question:
            logger.warning("ë¹ˆ ì§ˆë¬¸ìœ¼ë¡œ ìš”ì²­")
            raise HTTPException(status_code=400, detail="ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")

        # 1. ë²¡í„° ê²€ìƒ‰ìœ¼ë¡œ ì§ˆë¬¸ê³¼ ê°€ì¥ ê´€ë ¨ ë†’ì€ ë¬¸ì„œ ì¡°ê°(chunk)ì„ ì°¾ìŠµë‹ˆë‹¤.
        logger.info(f"ë²¡í„° DB ë¬¸ì„œ ìˆ˜: {len(vector_engine.list_documents())}")
        logger.info(f"ê²€ìƒ‰ ì „ ì»¬ë ‰ì…˜ ìƒíƒœ: {vector_engine.get_collection_stats()}")
        logger.info("ê´€ë ¨ ë¬¸ì„œ ì¡°ê° ê²€ìƒ‰ ì‹œì‘")
        relevant_chunks = vector_engine.search_documents(
            query=question,
            n_results=5,
            score_threshold=None
        )
        logger.info(f"ê´€ë ¨ ë¬¸ì„œ ì¡°ê° ê²€ìƒ‰ ì™„ë£Œ: {len(relevant_chunks)}ê°œ")

        if not relevant_chunks:
            logger.info("ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
            return JSONResponse({
                "response": "ì—…ë¡œë“œëœ ë¬¸ì„œì—ì„œ ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ í‚¤ì›Œë“œë¡œ ê²€ìƒ‰í•´ë³´ì„¸ìš”.",
                "sources": []
            })

        # 2. ì¤‘ë³µ ì œê±° ë° í’ˆì§ˆ í–¥ìƒëœ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
        logger.info("ì»¨í…ìŠ¤íŠ¸ êµ¬ì„± ì‹œì‘")
        context_parts = []
        source_filenames = set()
        for chunk in relevant_chunks:
            metadata = chunk.get('metadata', {})
            filename = metadata.get('filename', 'ì•Œ ìˆ˜ ì—†ëŠ” íŒŒì¼')
            context_parts.append(f"ë¬¸ì„œëª…: {filename}\në‚´ìš©:\n{chunk['content']}")
            source_filenames.add(filename)

        context = "\n\n---\n\n".join(context_parts)
        logger.info(f"ì»¨í…ìŠ¤íŠ¸ êµ¬ì„± ì™„ë£Œ: {len(context_parts)}ê°œ ì¡°ê°, {len(source_filenames)}ê°œ íŒŒì¼")

        # 3. êµ¬ì„±ëœ ì»¨í…ìŠ¤íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ AIì—ê²Œ ì§ˆë¬¸í•©ë‹ˆë‹¤.
        prompt = f"""ë‹¹ì‹ ì€ ë¬¸ì„œ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì•„ë˜ ì œê³µëœ ë¬¸ì„œ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ëŒ€í•´ ìƒì„¸í•˜ê³  ì¹œì ˆí•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”.

[ì œê³µëœ ë¬¸ì„œ ë‚´ìš©]
{context}

[ì§ˆë¬¸]
{question}

[ë‹µë³€ ì§€ì¹¨]
1. ë°˜ë“œì‹œ ì œê³µëœ ë¬¸ì„œ ë‚´ìš©ë§Œì„ ê·¼ê±°ë¡œ ë‹µë³€í•˜ì„¸ìš”
2. ë¬¸ì„œì—ì„œ ì§ì ‘ì ìœ¼ë¡œ ê´€ë ¨ëœ ë‚´ìš©ì´ ì—†ìœ¼ë©´ "ì œê³µëœ ë¬¸ì„œì—ì„œ í•´ë‹¹ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"ë¼ê³  ë‹µë³€í•˜ì„¸ìš”
3. ë‹µë³€í•  ë•ŒëŠ” êµ¬ì²´ì ì¸ ë‚´ìš©ê³¼ ì ˆì°¨ë¥¼ í¬í•¨í•˜ì„¸ìš”
4. ë¶ˆí™•ì‹¤í•˜ê±°ë‚˜ ì¶”ì¸¡ì„± ì •ë³´ëŠ” í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”
5. í•œêµ­ì–´ë¡œ ëª…í™•í•˜ê³  ì´í•´í•˜ê¸° ì‰½ê²Œ ë‹µë³€í•˜ì„¸ìš”

ë‹µë³€:"""

        logger.info("Ollama AIì— ìš”ì²­ ì „ì†¡")
        ollama_response = requests.post(
            f"{OLLAMA_HOST}/api/generate",
            json={
                "model": MODEL_NAME,
                "prompt": prompt,
                "stream": False,
                "options": {
                    "temperature": 0.3,  # ì°½ì˜ì„± ì¤„ì´ê³  ì •í™•ì„± í–¥ìƒ
                    "top_p": 0.9
                }
            },
            timeout=60
        )

        ollama_response.raise_for_status()
        logger.info("Ollama AI ì‘ë‹µ ìˆ˜ì‹  ì™„ë£Œ")

        ai_response = ollama_response.json()
        answer = ai_response.get("response", "ì˜¤ë¥˜: ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        logger.info(f"ì±„íŒ… ì‘ë‹µ ì™„ë£Œ: {len(answer)} ë¬¸ì, ì¶œì²˜: {sorted(list(source_filenames))}")
        return JSONResponse({
            "response": answer,
            "sources": sorted(list(source_filenames))
        })

    except requests.exceptions.RequestException as e:
        logger.error(f"AI ëª¨ë¸ ì„œë²„ ì—°ê²° ì‹¤íŒ¨: {str(e)}")
        raise HTTPException(status_code=503, detail=f"AI ëª¨ë¸ ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
    except Exception as e:
        logger.error(f"ì±„íŒ… ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        raise HTTPException(status_code=500, detail=f"ì±„íŒ… ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

@app.delete("/api/documents/{document_id}")
async def delete_document(document_id: str):
    logger.info(f"ë¬¸ì„œ ì‚­ì œ ìš”ì²­: {document_id}")

    # JSON íŒŒì¼ ê²½ë¡œ
    json_path = os.path.join(PROCESSED_DIR, f"{document_id}.json")

    if not os.path.exists(json_path):
        logger.error(f"ì‚­ì œí•  ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ: {document_id}")
        raise HTTPException(status_code=404, detail="ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    try:
        # ì›ë³¸ íŒŒì¼ ê²½ë¡œ ì°¾ê¸° ë° ì‚­ì œ
        logger.info(f"ë©”íƒ€ë°ì´í„° íŒŒì¼ ì½ê¸°: {json_path}")
        async with aiofiles.open(json_path, 'r', encoding='utf-8') as f:
            content = await f.read()
            doc_data = json.loads(content)

        original_filepath = doc_data.get('filepath')
        if original_filepath and os.path.exists(original_filepath):
            os.remove(original_filepath)
            logger.info(f"ì›ë³¸ íŒŒì¼ ì‚­ì œ ì™„ë£Œ: {original_filepath}")

        # JSON íŒŒì¼ ì‚­ì œ
        os.remove(json_path)
        logger.info(f"ë©”íƒ€ë°ì´í„° íŒŒì¼ ì‚­ì œ ì™„ë£Œ: {json_path}")

        # ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ë¬¸ì„œ ì‚­ì œ
        logger.info(f"ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ë¬¸ì„œ ì‚­ì œ ì‹œì‘: {document_id}")
        vector_engine.remove_document(document_id=document_id)
        logger.info(f"ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ë¬¸ì„œ ì‚­ì œ ì™„ë£Œ: {document_id}")

        logger.info(f"ë¬¸ì„œ ì‚­ì œ ì™„ë£Œ: {document_id}")
        return JSONResponse(content={"message": f"ë¬¸ì„œ(ID: {document_id})ê°€ ì„±ê³µì ìœ¼ë¡œ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤."})

    except Exception as e:
        logger.error(f"ë¬¸ì„œ ì‚­ì œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {document_id} - {str(e)}")
        raise HTTPException(status_code=500, detail=f"ë¬¸ì„œ ì‚­ì œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

# ë””ë²„ê¹…ì„ ìœ„í•œ ì„ì‹œ ë¼ìš°íŠ¸ ì¶”ê°€
@app.get("/api/debug/vector-stats")
async def get_vector_stats():
    """ë²¡í„° DB ìƒíƒœ ë””ë²„ê¹…ìš©"""
    try:
        stats = vector_engine.get_collection_stats()
        documents = vector_engine.list_documents()
        return JSONResponse({
            "stats": stats,
            "document_ids": documents,
            "total_documents": len(documents)
        })
    except Exception as e:
        return JSONResponse({"error": str(e)})

if __name__ == "__main__":
    print("ğŸš€ Document Search & Chat System ì‹œì‘!")
    print(f"ğŸ“ URL: http://localhost:8004")
    print(f"ğŸ¤– Ollama Host: {OLLAMA_HOST}")
    print(f"ğŸ“ Model: {MODEL_NAME}")
    print("=" * 50)

    logger.info("ì• í”Œë¦¬ì¼€ì´ì…˜ ì„œë²„ ì‹œì‘")
    uvicorn.run(app, host="localhost", port=8004, log_level="info")