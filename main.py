from fastapi import FastAPI, UploadFile, File, Form, HTTPException, Request
from fastapi.responses import HTMLResponse, JSONResponse
from fastapi.staticfiles import StaticFiles
from fastapi.templating import Jinja2Templates
import uvicorn
import os
import sys
from typing import List, Dict, Any
import json
import aiofiles
from datetime import datetime
import PyPDF2
import hashlib
import re
from app.services.vector_search import create_vector_search_engine

# ë²¡í„° ê²€ìƒ‰ ì—”ì§„ ì´ˆê¸°í™”
vector_engine = create_vector_search_engine()


# FastAPI ì•± ìƒì„±
app = FastAPI(title="Document Search & Chat System", version="1.0.0")

# ì •ì  íŒŒì¼ê³¼ í…œí”Œë¦¿ ì„¤ì •
app.mount("/static", StaticFiles(directory="static"), name="static")
templates = Jinja2Templates(directory="templates")

# ë””ë ‰í† ë¦¬ ì„¤ì •
UPLOAD_DIR = "uploads"
PROCESSED_DIR = "processed"
os.makedirs(UPLOAD_DIR, exist_ok=True)
os.makedirs(PROCESSED_DIR, exist_ok=True)

# Ollama ì„¤ì •
OLLAMA_HOST = "http://localhost:11434"
MODEL_NAME = "llama3.2:1b"

# ë¬¸ì„œ ì²˜ë¦¬ í´ë˜ìŠ¤
class DocumentProcessor:
    def __init__(self):
        pass
    
    def generate_document_id(self, filename: str) -> str:
        timestamp = str(int(datetime.now().timestamp() * 1000))
        unique_string = f"{filename}_{timestamp}"
        return hashlib.md5(unique_string.encode()).hexdigest()[:12]
    
    async def extract_pdf_text(self, file_path: str) -> str:
        try:
            with open(file_path, 'rb') as file:
                pdf_reader = PyPDF2.PdfReader(file)
                text = ""
                for page in pdf_reader.pages:
                    text += page.extract_text() + "\n"
                return text.strip()
        except Exception as e:
            raise Exception(f"PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨: {str(e)}")
    
    async def extract_txt_text(self, file_path: str) -> str:
        try:
            async with aiofiles.open(file_path, 'r', encoding='utf-8') as f:
                content = await f.read()
                return content.strip()
        except UnicodeDecodeError:
            try:
                async with aiofiles.open(file_path, 'r', encoding='cp949') as f:
                    content = await f.read()
                    return content.strip()
            except:
                async with aiofiles.open(file_path, 'r', encoding='latin-1') as f:
                    content = await f.read()
                    return content.strip()
    
    async def extract_docx_text(self, file_path: str) -> str:
        try:
            from docx import Document
            doc = Document(file_path)
            text = []
            for paragraph in doc.paragraphs:
                text.append(paragraph.text)
            return '\n'.join(text)
        except Exception as e:
            raise Exception(f"DOCX í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨: {str(e)}")



    async def process_file(self, file: UploadFile) -> Dict[str, Any]:
        try:
            if not file.filename:
                raise ValueError("íŒŒì¼ ì´ë¦„ì´ ì—†ìŠµë‹ˆë‹¤.")

            # íŒŒì¼ ì €ì¥
            file_path = os.path.join(UPLOAD_DIR, file.filename)
            async with aiofiles.open(file_path, 'wb') as f:
                content = await file.read()
                await f.write(content)

            ext = file.filename.lower().split('.')[-1]
            
            if ext == 'pdf':
                content = await self.extract_pdf_text(file_path)
            elif ext in ['txt', 'md']:
                content = await self.extract_txt_text(file_path)
            elif ext == 'docx':
                content = await self.extract_docx_text(file_path)
            else:
                raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹: {ext}")
            
            file_stats = os.stat(file_path)
            document_id = self.generate_document_id(file.filename)
            
            metadata = {
                'id': document_id,
                'filename': file.filename,
                'content': content,
                'size': file_stats.st_size,
                'upload_time': datetime.now().isoformat(),
                'file_type': ext,
                'word_count': len(content.split()),
                'char_count': len(content),
                'filepath': file_path
            }
            
            processed_file_path = os.path.join(PROCESSED_DIR, f"{document_id}.json")
            async with aiofiles.open(processed_file_path, 'w', encoding='utf-8') as f:
                await f.write(json.dumps(metadata, ensure_ascii=False, indent=2))
            
            return metadata
            
        except Exception as e:
            raise Exception(f"íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")

# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
doc_processor = DocumentProcessor()

# ë¼ìš°íŠ¸ë“¤
@app.get("/", response_class=HTMLResponse)
async def home(request: Request):
    return templates.TemplateResponse("index.html", {"request": request})

@app.post("/api/upload")
async def upload_file(file: UploadFile = File(...)):
    if not file.filename:
        raise HTTPException(status_code=400, detail="íŒŒì¼ ì´ë¦„ì´ ì—†ìŠµë‹ˆë‹¤.")

    # íŒŒì¼ ì²˜ë¦¬
    doc_data = await doc_processor.process_file(file)

    # (ìˆ˜ì •) ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì— ë¬¸ì„œ ì¶”ê°€
    try:
        vector_engine.add_document(
            document_id=doc_data["id"],
            content=doc_data["content"],
            metadata=doc_data
        )
    except Exception as e:
        # ë§Œì•½ ë²¡í„° DB ì¶”ê°€ì— ì‹¤íŒ¨í•˜ë©´ ì´ë¯¸ ì €ì¥ëœ íŒŒì¼ì„ ì •ë¦¬
        if os.path.exists(doc_data['filepath']):
            os.remove(doc_data['filepath'])
        if os.path.exists(os.path.join(PROCESSED_DIR, f"{doc_data['id']}.json")):
            os.remove(os.path.join(PROCESSED_DIR, f"{doc_data['id']}.json"))
        raise HTTPException(status_code=500, detail=f"ë¬¸ì„œ ë²¡í„°í™” ì‹¤íŒ¨: {e}")

    return JSONResponse(
        status_code=201,
        content={
            "message": "íŒŒì¼ ì—…ë¡œë“œ ë° ì²˜ë¦¬ ì„±ê³µ",
            "document": doc_data
        }
    )

@app.get("/api/documents")
async def get_documents():
    try:
        documents = []
        for filename in os.listdir(PROCESSED_DIR):
            if filename.endswith('.json'):
                file_path = os.path.join(PROCESSED_DIR, filename)
                async with aiofiles.open(file_path, 'r', encoding='utf-8') as f:
                    content = await f.read()
                    doc_data = json.loads(content)
                    doc_summary = {k: v for k, v in doc_data.items() if k != 'content'}
                    documents.append(doc_summary)
        
        documents.sort(key=lambda x: x['upload_time'], reverse=True)
        return JSONResponse({"documents": documents})
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ë¬¸ì„œ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")

@app.post("/api/search")
async def search_documents(request: Request):
    try:
        data = await request.json()
        query = data.get("query", "").strip()

        if not query:
            raise HTTPException(status_code=400, detail="ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")

        # ë²¡í„° ê²€ìƒ‰ì„ í†µí•´ ì˜ë¯¸ì ìœ¼ë¡œ ìœ ì‚¬í•œ ë¬¸ì„œ ì¡°ê°ì„ ê²€ìƒ‰í•©ë‹ˆë‹¤.
        vector_results = vector_engine.search_documents(
            query=query,
            n_results=10,
            score_threshold=0.3 # ìœ ì‚¬ë„ ì ìˆ˜ ì„ê³„ê°’
        )

        # í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ì‚¬ìš©í•  í˜•ì‹ìœ¼ë¡œ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ê°€ê³µí•©ë‹ˆë‹¤.
        results = []
        for res in vector_results:
            metadata = res.get('metadata', {})
            # content_snippet í‚¤ë¥¼ ì‚¬ìš©í•˜ì—¬ í”„ë¡ íŠ¸ì—”ë“œì— ì „ë‹¬í•©ë‹ˆë‹¤.
            snippet = res.get('content', '')
            highlighted_snippet = re.sub(
                re.escape(query),
                f"<mark>{query}</mark>",
                snippet,
                flags=re.IGNORECASE
            )
            
            results.append({
                "id": metadata.get("id"),
                "filename": metadata.get("filename"),
                "file_type": metadata.get("file_type"),
                "upload_time": metadata.get("upload_time"),
                "content_snippet": highlighted_snippet # JSì—ì„œ ì‚¬ìš©í•˜ëŠ” í‚¤
            })

        return JSONResponse({
            "query": query,
            "results": results,
            "total_results": len(results) # JSì—ì„œ ì‚¬ìš©í•˜ëŠ” í‚¤
        })

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}")

@app.post("/api/chat")
async def chat_with_documents(request: Request):
    try:
        import requests
        
        data = await request.json()
        question = data.get("message", "").strip()  # "question" â†’ "message"ë¡œ ë³€ê²½
        
        if not question:
            raise HTTPException(status_code=400, detail="ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        
        # 1. ë²¡í„° ê²€ìƒ‰ìœ¼ë¡œ ì§ˆë¬¸ê³¼ ê°€ì¥ ê´€ë ¨ ë†’ì€ ë¬¸ì„œ ì¡°ê°(chunk)ì„ ì°¾ìŠµë‹ˆë‹¤.
        relevant_chunks = vector_engine.search_documents(
            query=question,
            n_results=5,  # AIì—ê²Œ ì „ë‹¬í•  ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ ì¡°ê° 5ê°œ
            score_threshold=0.4
        )
        
        if not relevant_chunks:
            return JSONResponse({
                "response": "ì—…ë¡œë“œëœ ë¬¸ì„œì—ì„œ ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",  # "answer" â†’ "response"ë¡œ ë³€ê²½
                "sources": []
            })
            
        # 2. ê²€ìƒ‰ëœ ì¡°ê°ë“¤ì„ ë°”íƒ•ìœ¼ë¡œ AIì—ê²Œ ì „ë‹¬í•  ì»¨í…ìŠ¤íŠ¸(context)ë¥¼ êµ¬ì„±í•©ë‹ˆë‹¤.
        context_parts = []
        source_filenames = set()
        for chunk in relevant_chunks:
            metadata = chunk.get('metadata', {})
            filename = metadata.get('filename', 'ì•Œ ìˆ˜ ì—†ëŠ” íŒŒì¼')
            context_parts.append(f"ë¬¸ì„œëª…: {filename}\në‚´ìš©:\n{chunk['content']}")
            source_filenames.add(filename)
            
        context = "\n\n---\n\n".join(context_parts)
        
        # 3. êµ¬ì„±ëœ ì»¨í…ìŠ¤íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ AIì—ê²Œ ì§ˆë¬¸í•©ë‹ˆë‹¤.
        prompt = f"""ë‹¹ì‹ ì€ ë¬¸ì„œ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì•„ë˜ ì œê³µëœ ë¬¸ì„œ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ëŒ€í•´ ìƒì„¸í•˜ê³  ì¹œì ˆí•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”.

[ì œê³µëœ ë¬¸ì„œ ë‚´ìš©]
{context}

[ì§ˆë¬¸]
{question}

[ë‹µë³€ ì¡°ê±´]
- ë°˜ë“œì‹œ ì œê³µëœ ë¬¸ì„œ ë‚´ìš©ì— ê·¼ê±°í•˜ì—¬ ë‹µë³€í•´ì•¼ í•©ë‹ˆë‹¤.
- ë¬¸ì„œì— ê´€ë ¨ ë‚´ìš©ì´ ì—†ìœ¼ë©´ "ì œê³µëœ ë¬¸ì„œì˜ ë‚´ìš©ë§Œìœ¼ë¡œëŠ” ë‹µë³€í•˜ê¸° ì–´ë µìŠµë‹ˆë‹¤."ë¼ê³  ì†”ì§í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”.
- ë‹µë³€ì€ í•œêµ­ì–´ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
- ê°œì¸ì •ë³´, ì‹ ì› í™•ì¸ì„œ ë“±ì˜ ìš©ì–´ê°€ ë‚˜ì˜¤ë©´ ë°˜ë“œì‹œ ë¬¸ì„œì˜ ì •í™•í•œ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”."""

        ollama_response = requests.post(
            f"{OLLAMA_HOST}/api/generate",
            json={
                "model": MODEL_NAME,
                "prompt": prompt,
                "stream": False
            },
            timeout=60  # ì‘ë‹µ ì‹œê°„ì„ ë„‰ë„‰í•˜ê²Œ ì„¤ì •
        )
        
        ollama_response.raise_for_status()
        
        ai_response = ollama_response.json()
        answer = ai_response.get("response", "ì˜¤ë¥˜: ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        return JSONResponse({
            "response": answer,  # "answer" â†’ "response"ë¡œ ë³€ê²½
            "sources": sorted(list(source_filenames))
        })
        
    except requests.exceptions.RequestException as e:
        raise HTTPException(status_code=503, detail=f"AI ëª¨ë¸ ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ì±„íŒ… ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

@app.delete("/api/documents/{document_id}")
async def delete_document(document_id: str):
    # JSON íŒŒì¼ ê²½ë¡œ
    json_path = os.path.join(PROCESSED_DIR, f"{document_id}.json")

    if not os.path.exists(json_path):
        raise HTTPException(status_code=404, detail="ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    try:
        # ì›ë³¸ íŒŒì¼ ê²½ë¡œ ì°¾ê¸° ë° ì‚­ì œ
        async with aiofiles.open(json_path, 'r', encoding='utf-8') as f:
            content = await f.read()
            doc_data = json.loads(content)
        
        original_filepath = doc_data.get('filepath')
        if original_filepath and os.path.exists(original_filepath):
            os.remove(original_filepath)
        
        # JSON íŒŒì¼ ì‚­ì œ
        os.remove(json_path)
        
        # (ìˆ˜ì •) ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ë¬¸ì„œ ì‚­ì œ
        vector_engine.remove_document(document_id=document_id)

        return JSONResponse(content={"message": f"ë¬¸ì„œ(ID: {document_id})ê°€ ì„±ê³µì ìœ¼ë¡œ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤."})

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ë¬¸ì„œ ì‚­ì œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

if __name__ == "__main__":
    print("ğŸš€ Document Search & Chat System ì‹œì‘!")
    print(f"ğŸ“ URL: http://localhost:8004")
    print(f"ğŸ¤– Ollama Host: {OLLAMA_HOST}")
    print(f"ğŸ“ Model: {MODEL_NAME}")
    print("=" * 50)
    
    uvicorn.run(app, host="localhost", port=8004, log_level="info")